#summary JAQL built-in function list - autogenerated
#labels generated
#sidebar TableOfContents
<wiki:toc max_depth="2" />
=system=
== batch() ==

  _*Description*_ batch( [T] A , long n ) returns [[T]] 
 
 Takes an array A and groups it arbitrarily into blocks of size <= n.
 Typically the last every block but the last block has size n, but
 batch can be run in parallel and could produce more small blocks.
 
 Example:
 
 range(1,10) -> batch(3);
 ==> [ [1,2,3], [4,5,6], [7,8,9], [10] ]

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== R() ==

  _*Description*_ A function allowing invocation of R from within Jaql.
 
 R(fn, args=[item arg1, ..., item argN], 
 inSchema=[schema arg1, ...,schema argN], outSchema=null, 
 init, initInline=true, binary=false, flexible=false)
 
 A single R process is forked per RFn instance (i.e., call site in the query).
 The R process is forked and the init script/string is passed to R only on the 
 first invocation.
 
 To configure R, add -DR.home=<path to R> and -DR.args=<args to R> to the 
 VM arguments. 
 
 // TODO: need jaql.conf

  _*Parameters*_ (1 - 8 inputs)
 Input Types: {{{( fn, required: schema string),( args = null: schema [ * ]?),( inSchema = null: schema [ * ]?),( outSchema = null: schema schematype?),( init = null: schema string?),( initInline = true: schema boolean),( binary = false: schema boolean),( flexible = false: schema boolean)}}}

 _*Output*_ {{{schema any}}}

----
=pragma=
== const() ==

  _*Description*_ This is a pragma function to force const evaluation.

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== inline() ==

  _*Description*_ This is a pragma function to force let/global inlining.

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== unrollLoop() ==

  _*Description*_ A pragma to encourage loop unrolling.

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

----
=del=
== jsonToDel() ==

  _*Description*_ A function for converting JSON to CSV. It is called as follows:
 <p>
 <code>jsonToDel({schema: '...', delimiter: '...', quoted: '...', escape: '...'})</code> .

  _*Parameters*_ (1 - 2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

----
=core=
== daisyChain() ==

  _*Description*_ Calls the composition of a set of single argument functions.
 
 daisyChain(T0 input, [f1, f2, ..., fn]) returns Tn
 
 where:
   f1(T0) returns T1,
   f2(T1) returns T2,
   fn(Tn) returns Tn
   
 A compose function that returns a function is easily created from this one:
   compose = fn(fns) fn(input) daisyChain(input, fns)

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== diamondTag() ==

  _*Description*_ This function is used internally during the rewriting of tee().  
 It is not intended for general use.
 
 e -> tagDiamond( f0, ..., fn )
 
 Exactly the same as:
   e -> expand union( [$] -> f0() -> transform [0,$], ..., 
                      [$] -> fn() -> transform [n,$] )

  _*Parameters*_ (2 - 3 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any),( arg2 = null: schema any)...}}}

 _*Output*_ {{{schema any}}}

== expectException() ==

  _*Description*_ This function is used by tests to mask expected exceptions.

  _*Parameters*_ (1 - 2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any)...}}}

 _*Output*_ {{{schema any}}}

== groupCombine() ==

  _*Description*_ groupCombine(input $X, initialFn, partialFn, finalFn) => $Y
    initialFn = fn($k,$X) e1 => $P
    partialFn = fn($k,$P) => $P
    finalFn = fn($k,$P) => $Y

  _*Parameters*_ (4 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any),( arg2, required: schema any),( arg3, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== jump() ==

  _*Description*_ jump(i, e0, ..., en) return one of e0 to en based on i.
 i must be exactly one of 0...n
 Like 'if', it should only evaluate one of e0 to en.
 
 Exactly the same as:
   if( i == 0 ) e0
   else if( i == 1 ) e1
   ...
   else if( i == n ) en
   else raise error

  _*Parameters*_ (2 - 3 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any),( arg2 = null: schema any)...}}}

 _*Output*_ {{{schema any}}}

== perf() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== retag() ==

  _*Description*_ This function is used internally during the rewriting of tee().  
 It is not intended for general use.
 
 e -> retag( f1, ..., fn )
 
 Exactly the same as:
   e -> expand ( jump($[0], f1, ..., fn)( [$[1]] ) -> transform[i,$[0]] )

  _*Parameters*_ (2 - 3 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any),( arg2 = null: schema any)...}}}

 _*Output*_ {{{schema any}}}

== skipUntil() ==

  _*Description*_ Skip the first elements of input (in order) until the predicate is true,
 return all elements after the test fires.
 If inclusive is true (the default) then return the element that triggered
 the condition.  Otherwise, exclude it. 
 
 input: [T...]? -> skipUntil( when: fn(T): bool, inclusive:bool = true ): [T...]

  _*Parameters*_ (2 - 3 inputs)
 Input Types: {{{( input, required: schema [ * ]?),( when, required: schema function),( inclusive = true: schema boolean?)}}}

 _*Output*_ {{{schema [ * ]}}}

== streamSwitch() ==

  _*Description*_ e0 -> streamSwitch( f0, ..., fn )
 ===
 ( x = e0,
   union( x -> filter $[0] == 0 -> transform $[1] -> f0(),
          ...
          x -> filter $[0] == n -> transform $[1] -> fn() ) 
 )
 
 Except that the functions can be called any number of times and in any order.
 Something like this:
 
 ( x = e0,
   union( x -> filter $[0] == 0 -> transform $[1] -> batch(n=?) -> expand f0($),
          ...
          x -> filter $[0] == n -> transform $[1] -> batch(n=?) -> expand fn($) ) 
 )
 
 The actual implementation is to stream into function fi any consecutive rows
 with index i.  Something like this:
 
 ( x = e0,
   x -> tumblingWindow( stop = fn(first,next) first[0] != next[0] )
     -> expand each p fi( p -> transform $[1] ) // where i is p[j][0] for all j in the window
 )

  _*Parameters*_ (2 - 3 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any),( arg2 = null: schema any)...}}}

 _*Output*_ {{{schema any}}}

== tag() ==

  _*Description*_ This function is used internally during the rewriting of tee().  
 It is not intended for general use.
 
 e -> tag(i)
 
 Exactly the same as:
   e -> transform [i,$]

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== tagFlatten() ==

  _*Description*_ This function is used internally during the rewriting of tee().  
 It is not intended for general use.
 
 e -> tagFlatten( int index, int numToExpand )
 
 Exactly the same as:
   e -> transform each x (
         i = x[0],
         v = x[1],
         if( i < index ) then x
         else if( i > index ) then [i + numToExpand-1, v]
         else ( assert(0 <= v[0] < numToExpand), [ v[0] + index, v[1] ] ))
 
 Example:
   [ [0,a], [1,[0,b]], [1,[1,c]], [2,d] ] -> tagFlatten( 1, 2 )
  ==
   [ [0,a], [1,b], [2,c], [3,d] ]

  _*Parameters*_ (3 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any),( arg2, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== tagSplit() ==

  _*Description*_ This function is used internally during the rewriting of tee().  
 It is not intended for general use.
 
 e -> tagSplit( f0, ..., fn )
 
 Exactly the same as:
   ( X = e, 
     X -> filter $[0] == 0 -> f0() -> transform $[1], ...
     X -> filter $[0] == n -> fn() -> transform $[1] )
     
 Also the same as:
   ( e -> write( composite( [t0, ..., tn] ) ),
     read(t0) -> f0(), ...
     read(tn) -> fn() )

  _*Parameters*_ (2 - 3 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any),( arg2 = null: schema any)...}}}

 _*Output*_ {{{schema any}}}

== until() ==

  _*Description*_ Return the first elements of input (in order) until the predicate is true.
 If inclusive is true (the default) then include the element that triggered
 the condition.  Otherwise, exclude it. 
 
 input: [T...]? -> until( when: fn(T): bool, inclusive:bool = true ): [T...]

  _*Parameters*_ (2 - 3 inputs)
 Input Types: {{{( input, required: schema [ * ]?),( when, required: schema function),( inclusive = true: schema boolean?)}}}

 _*Output*_ {{{schema [ * ]}}}

----
=hadoop=
== buildModel() ==

  _*Description*_ Build a data mining model in parallel.
 
 buildModel( 
 { input: fd,
   output: fd,  // TODO: this could be eliminated, but required now and gets model
   init: fn() -> model,
   partial: fn($part,$model) -> pmodel, // $part is array of input items
   combine: fn($pmodels,$model) -> model, // $pmodels is array of partial models
   done: fn($oldModel, $newModel) -> bool
  })
 -> model

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== chainedMap() ==

  _*Description*_ Run a function *sequentially* but piecemeal over an input array.
 
 chainedMap( 
 { input: fd,
   output: fd,  // TODO: this could be eliminated, but required now and gets state
   init: state,
   map: fn(part,state) -> state, // part is array of input items
   schema?: state schema
  })
 -> state

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

----
=io=
== arrayRead() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== expandFD() ==

  _*Description*_ 

  _*Parameters*_ (1 - 2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

== http() ==

  _*Description*_ An expression that constructs an I/O descriptor for local file access.

  _*Parameters*_ (1 - 3 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any),( arg2 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

== httpGet() ==

  _*Description*_ 

  _*Parameters*_ (1 - 3 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any),( arg2 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

----
=array=
== append() ==

  _*Description*_ append($a, $b, ...) ==> unnest [ $a, $b, ... ] NOT when $a or $b are
 non-array (and non-null), but that's probably an improvement. NOT when $a or
 $b are null, but the change to unnest to remove nulls will fix that should
 append(null, null) be null? it would break any unnest definition... Push
 unnest into ListExpr?

  _*Parameters*_ (1 - 2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any)...}}}

 _*Output*_ {{{schema any}}}

== columnwise() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== rowwise() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== runningCombine() ==

  _*Description*_ 

  _*Parameters*_ (4 inputs)
 Input Types: {{{( input, required: schema [ * ]?),( init, required: schema any),( add, required: schema function),( into, required: schema function?)}}}

 _*Output*_ {{{schema [ * ]}}}

----
=index=
== buildJIndex() ==

  _*Description*_ 

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== probeJIndex() ==

  _*Description*_ 

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== sharedHashtableN() ==

  _*Description*_ sharedHashtableN(
     [Key] probeKeys,
     string buildUrl, // "hash://host:port/tableid",
     fn() returns [ [Key,Value] ] buildFn,
     schema [Key, Value] buildSchema ) // TODO: should be inferred from buildFn OR template params 
   returns [Key,Value]

 
 The file represented by fd must have [key,value2] pairs.
 The [key,value2] pairs are loaded into a hash table
 If the fd is same from call to call, the table is not reloaded.
   // TODO: cache multiple tables? perhaps with weak references
   // TODO: use hadoop's distributed cache?
   
 It is generally assumed that the file is assessible wherever this
 function is evaluated.  If it is automatically parallelized, the
 file better be available from every node (eg, in hdfs).

 Throws an exception if the file contains duplicate keys
 
 If the probe key does not exist in the hashtable, null is returned.

  _*Parameters*_ (4 - 10 inputs)
 Input Types: {{{( data, required: schema [
         [ * ]? * 
       ]?),( url, required: schema [ * ]?),( buildFn, required: schema [ * ]?),( buildSchema, required: schema [ * ]?),( age = -1: schema long),( lease = 0: schema long),( serverStart = true: schema boolean),( serverTimeout = 300000: schema long),( serverMemory = "500M": schema string),( serverThread = false: schema boolean)}}}

 _*Output*_ {{{schema [
         [
           any,
           any
         ] * 
       ]}}}

----
=schema=
== assert() ==

  _*Description*_ Returns its first argument and adds the schema information given in the second argument
 without validation. Use carefully!

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== dataGuide() ==

  _*Description*_ Usage: dataGuide(any value) returns [string]
 
 Return a string that represents each unique path in the value.
 For records:
    yield ""
    for each field:value in record:
       yield "." + field + dataGuide(value)
 For arrays:
    yield "[]"
    for each value in array
       yield "[]" + dataGuide(value) 
 For atomic types:
     yield ":" + the type name, eg, ":string", ":null"

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== elementsOf() ==

  _*Description*_ elementsOf(schema): if schema is (potentially) an array schema, return the schema of its elements (if any)

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== fieldsOf() ==

  _*Description*_ elementsOf(schema): if schema is (potentially) an record schema, return a table describing its known fields:
     [{ name: string, schema: schema, index: long }...]

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== isNullable() ==

  _*Description*_ isNullable(schema): true if schema might match null, false otherwise

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== schemaof() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== sqlTypeCode() ==

  _*Description*_ sqlTypeCode(schema): return the sql type code for schema

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

----
=internal=
== exprtree() ==

  _*Description*_ An internal method that can be used to print the internal tree of expressions in JSON format.

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== hash() ==

  _*Description*_ An internal method that can be used to print the internal tree of expressions in JSON format.

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== longHash() ==

  _*Description*_ An internal method that can be used to print the internal tree of expressions in JSON format.

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

----
=nil=
== emptyOnNull() ==

  _*Description*_ emptyOnNull(e) == firstNonNull(e, [])

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== firstNonNull() ==

  _*Description*_ 

  _*Parameters*_ (0 - 1 inputs)
 Input Types: {{{( arg0 = null: schema any)...}}}

 _*Output*_ {{{schema any}}}

== nullElementOnEmpty() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== nullOnEmpty() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== onEmpty() ==

  _*Description*_ 

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

----
=db=
== jdbc() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

----
=catalog=
== catalogInsert() ==

  _*Description*_ An expression to insert an entry into catalog. It is an error if an entry
 with the same key already exists.

  _*Parameters*_ (1 - 2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

== catalogLookup() ==

  _*Description*_ An expression to read the entry identified by a key in catalog.

  _*Parameters*_ (1 - 2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

== catalogUpdate() ==

  _*Description*_ An expression to update catalog entry. It can only add records or fields. No
 old records or fields will be overwritten.

  _*Parameters*_ (1 - 2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

== updateComment() ==

  _*Description*_ An expression that updates comment field of entry in catalog.

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

----
=agg=
== combine() ==

  _*Description*_ 

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== covStats() ==

  _*Description*_ covStats(array x) = sum [1 x1 x2 ... xn] * [1 x1 x2 ... xn]^T
   = [ count   sum(x1)    sum(x2)    ... sum(xn)    ,
               sum(x1*x1) sum(x1*x2) ... sum(x1*xn) ,
                          sum(x2*x2) ... sum(x2*xn) ,
       ...                                          ,
                                         sum(xn*xn) ]

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== expSmooth() ==

  _*Description*_ Perform exponential smoothing on a sequence of numbers:
   s[0] = x[0]
   s[i] = a * x[i] + (1-a) * s[i-1]
 The numbers are cast to a double and the result is always a double.

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== icebergCubeInMemory() ==

  _*Description*_ 

  _*Parameters*_ (3 - 4 inputs)
 Input Types: {{{( input, required: schema [ * ]?),( columns, required: schema [
         string * 
       ]),( perGroupFn, required: schema function),( minSupport = 1: schema long | double | decfloat)}}}

 _*Output*_ {{{schema [
         [ * ] * 
       ]}}}

== inferElementSchema() ==

  _*Description*_ Infer a schema that describes all of the elements.

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== vectorSum() ==

  _*Description*_ vectorSum(array x) = [sum(x1), sum(x2), ..., sum(xn)]

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

----
=span=
== span() ==

  _*Description*_ 

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== span_begin() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== span_contains() ==

  _*Description*_ 

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== span_end() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== span_extract() ==

  _*Description*_ span_extract("some big string", span(2,4))
 "me"
 
 Current implementation uses SubJsonString. If the caller modifies the input string at
 some later point, the result of this call will be invalid.

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== span_overlaps() ==

  _*Description*_ 

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== span_select() ==

  _*Description*_ 

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== tokenize() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

----
=module=
== examples() ==

  _*Description*_ 

  _*Parameters*_ (1 - 2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

== listExports() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== test() ==

  _*Description*_ 

  _*Parameters*_ (1 - 2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

----
=function=
== addClassPath() ==

  _*Description*_ Add jars to the classpath

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== fencePush() ==

  _*Description*_ evaluate a function in a separate process
 Usage:
 T2 fencePush( T1 e,  T2 fn(T1 x) );

 The fencePush function applies the function argument to e to produce the output. 
 In particular, the fencePush function is evaluated in a separate process. 
 In contrast to fence, where all of the input is consumed, fencePush is designed
 to be pushed one value at a time (e.g., as in the case of transform). For such
 cases, the fencePush process will be re-used between calls.
 A common use of fencePush is to shield the Jaql interpreter from user-defined 
 functions that exhaust memory, for example.

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

  _*Examples*_ 
{{{
jaql> [1,2,3] -> write(hdfs("test"));

jaql> read(hdfs("test")) -> transform fencePush( $, fn(i) i + 1 );
 [2,3,4]

}}}
----
=net=
== jaqlGet() ==

  _*Description*_ 

  _*Parameters*_ (1 - 2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

----
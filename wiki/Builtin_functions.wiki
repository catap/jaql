#summary JAQL built-in function list - autogenerated
#labels generated
#sidebar TableOfContents
<wiki:toc max_depth="2" />
=system=
== batch() ==

  _*Description*_ batch( [T] A , long n ) returns [[T]] 
 
 Takes an array A and groups it arbitrarily into blocks of size <= n.
 Typically the last every block but the last block has size n, but
 batch can be run in parallel and could produce more small blocks.
 
 Example:
 
 range(1,10) -> batch(3);
 ==> [ [1,2,3], [4,5,6], [7,8,9], [10] ]

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== exec() ==

  _*Description*_ 

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== externalfn() ==

  _*Description*_ An expression that constructs a JSON value for a Java UDF

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== ls() ==

  _*Description*_ ls(glob)

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== R() ==

  _*Description*_ A function allowing invocation of R from within Jaql.
 
 R(fn, args=[item arg1, ..., item argN], 
 inSchema=[schema arg1, ...,schema argN], outSchema=null, 
 init, initInline=true, binary=false, flexible=false)
 
 A single R process is forked per RFn instance (i.e., call site in the query).
 The R process is forked and the init script/string is passed to R only on the 
 first invocation.
 
 To configure R, add -DR.home=<path to R> and -DR.args=<args to R> to the 
 VM arguments. 
 
 // TODO: need jaql.conf

  _*Parameters*_ (1 - 8 inputs)
 Input Types: {{{( fn, required: schema string),( args = null: schema [ * ]?),( inSchema = null: schema [ * ]?),( outSchema = null: schema schematype?),( init = null: schema string?),( initInline = true: schema boolean),( binary = false: schema boolean),( flexible = false: schema boolean)}}}

 _*Output*_ {{{schema any}}}

----
=pragma=
== const() ==

  _*Description*_ This is a pragma function to force const evaluation.

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== inline() ==

  _*Description*_ This is a pragma function to force let/global inlining.

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== unrollLoop() ==

  _*Description*_ A pragma to encourage loop unrolling.

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

----
=core=
== catch() ==

  _*Description*_ Wrap any expression with catch to guard against exceptions.
 Usage:
 
 T1|null catch( T1 e1, { errThresh: long } | null, T2 e2);
 
 Wrap the catch expression around the first argument, e1, that needs to be guarded
 for exceptions. 
 
 The second argument is optional. It specifies an exception handling policy. If unspecified or null, the default
 exception handling policy is used. By default, if an exception occurs, it is propagated
 (which typically results in aborted execution). This default can be overridden globally
 using the registerExceptionHandler function, or at can be overridden per usage of catch
 by using the second argument. Such an override allows catch to throw an exception errThresh
 times before propagating the exception. Thus, the default has errThresh set to 0.
 
 The third argument, e2, is optional and is used to specify an expression whose value is logged when an exception
 is thrown.
 
 Catch returns the result of evaluating e1 (whose type is T1). If an exception is thrown, but
 skipped, then null is returned.
 
 Note that catch s a "blocking" call: the result of e1 will be materialized. If e1 could
 be streamed (e.g., read(...)), when used in the context of catch, its result will be entirely
 materialized.

  _*Parameters*_ (1 - 3 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any),( arg2 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

  _*Examples*_ 
{{{
jaql> data = [ ["a",0], ["a",1], ["b",0], ["c",0], ["c",1], ["c",2]];

jaql> data -> write(hdfs("test"));

jaql> read(hdfs("test"))
      -> transform catch(if ($[0] == "a") ($.badFieldAccess) // cause exceptions on ["a", 0] and ["a", 1]
                         else ($), 
                         { errThresh: 1000 }) 
      -> group by g = $[0] 
         into { g: g, 
                num: count($), 
                err: catch(if(g == "b") (g.badFieldAccess) // cause exception/null on the "b" group
                           else ("ok"), 
                           { errThresh: 1000 }) 
              }; 
[
 {
   "err": "ok",
   "g": null,
   "num": 2
  },
  {
   "err": null,
   "g": "b",
   "num": 1
  },
  {
   "err": "ok",
   "g": "c",
   "num": 3
  }
]

}}}
== compare() ==

  _*Description*_ 

  _*Parameters*_ (2 inputs)
 Input Types: {{{( x, required: schema any),( y, required: schema any)}}}

 _*Output*_ {{{schema long}}}

== daisyChain() ==

  _*Description*_ Calls the composition of a set of single argument functions.
 
 daisyChain(T0 input, [f1, f2, ..., fn]) returns Tn
 
 where:
   f1(T0) returns T1,
   f2(T1) returns T2,
   fn(Tn) returns Tn
   
 A compose function that returns a function is easily created from this one:
   compose = fn(fns) fn(input) daisyChain(input, fns)

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== diamondTag() ==

  _*Description*_ This function is used internally during the rewriting of tee().  
 It is not intended for general use.
 
 e -> tagDiamond( f0, ..., fn )
 
 Exactly the same as:
   e -> expand union( [$] -> f0() -> transform [0,$], ..., 
                      [$] -> fn() -> transform [n,$] )

  _*Parameters*_ (2 - 3 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any),( arg2 = null: schema any)...}}}

 _*Output*_ {{{schema any}}}

== expectException() ==

  _*Description*_ This function is used by tests to mask expected exceptions.

  _*Parameters*_ (1 - 2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any)...}}}

 _*Output*_ {{{schema any}}}

== getHdfsPath() ==

  _*Description*_ return the absolute path in HDFS

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== getOptions() ==

  _*Description*_ Return the system options record.

  _*Parameters*_ (0 inputs)
 Input Types: {{{}}}

 _*Output*_ {{{schema any}}}

== groupCombine() ==

  _*Description*_ groupCombine(input $X, initialFn, partialFn, finalFn) => $Y
    initialFn = fn($k,$X) e1 => $P
    partialFn = fn($k,$P) => $P
    finalFn = fn($k,$P) => $Y

  _*Parameters*_ (4 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any),( arg2, required: schema any),( arg3, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== index() ==

  _*Description*_ element(array, index) is the same as array[index], but it captures a simpler 
 case that doesn't use path expressions. array[index] is transformed to use the
 element function for better performance.

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== jump() ==

  _*Description*_ jump(i, e0, ..., en) return one of e0 to en based on i.
 i must be exactly one of 0...n
 Like 'if', it should only evaluate one of e0 to en.
 
 Exactly the same as:
   if( i == 0 ) e0
   else if( i == 1 ) e1
   ...
   else if( i == n ) en
   else raise error

  _*Parameters*_ (2 - 3 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any),( arg2 = null: schema any)...}}}

 _*Output*_ {{{schema any}}}

== listVariables() ==

  _*Description*_ List the active global variables.
   [{ var: string, schema: schema, isTable: boolean }...]

  _*Parameters*_ (0 inputs)
 Input Types: {{{}}}

 _*Output*_ {{{schema [
         {
           "var": string,
           "schema": schematype,
           "isTable": boolean
         } * 
       ]}}}

== mergeContainers() ==

  _*Description*_ DEPRECATED: is this used anywhere?
 Merge a set of arrays into one array in order, or a set of records into one record.  Nulls are ignored.

  _*Parameters*_ (1 - 2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any)...}}}

 _*Output*_ {{{schema any}}}

== perf() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== perPartition() ==

  _*Description*_ 

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== range() ==

  _*Description*_ Range generates a continuous array of numbers
 
 Usage:
 range(size)      = [0,size-1]
 range(size,null) = [0,size-1]
 range(start,end) = [start,end]
 range(start,end,skip) = if skip > 0 then for(i = start, i <= end, i += skip)
                         else error
 range(size,null,skip) = if skip > 0 then for(i = 0, i < size, i += skip)
                         else error

  _*Parameters*_ (1 - 3 inputs)
 Input Types: {{{( startOrSize, required: schema long?),( end = null: schema long?),( by = 1: schema long)}}}

 _*Output*_ {{{schema [
         long * 
       ]}}}

== registerExceptionHandler() ==

  _*Description*_ Register a default exception handling policy.
 Usage:
 
 bool registerExceptionHandler( { errThresh: long } );
 
 This function allows the default exception handling policy to be overridden.
 Currently, the policy can specify how many exceptions to skip before propagating
 the exception up the call stack. This is specified by the errThresh field of the
 input. By default, errThresh is set to 0, meaning that no exceptions are skipped.
 
 When an exception is skipped, the enclosing expression decides what to do. If the
 exception occurs in the catch function, then it returns null and logs the results of
 a user supplied expression. If the exception occurs in a transform, then the result is
 skipped and logged.

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

  _*Examples*_ 
{{{
jaql> registerExceptionHandler({errThresh: 5});

jaql> data = [ ["a",0], ["a",1], ["b",0], ["c",0], ["c",1], ["c",2]];

jaql> data -> write(hdfs("test"));

jaql> read(hdfs("test")) -> filter $[1] == 0 -> transform $.badTypeAssumption;
 []

}}}
== retag() ==

  _*Description*_ This function is used internally during the rewriting of tee().  
 It is not intended for general use.
 
 e -> retag( f1, ..., fn )
 
 Exactly the same as:
   e -> expand ( jump($[0], f1, ..., fn)( [$[1]] ) -> transform[i,$[0]] )

  _*Parameters*_ (2 - 3 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any),( arg2 = null: schema any)...}}}

 _*Output*_ {{{schema any}}}

== setOptions() ==

  _*Description*_ Set system options.

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== skipUntil() ==

  _*Description*_ Skip the first elements of input (in order) until the predicate is true,
 return all elements after the test fires.
 If inclusive is true (the default) then return the element that triggered
 the condition.  Otherwise, exclude it. 
 
 input: [T...]? -> skipUntil( when: fn(T): bool, inclusive:bool = true ): [T...]

  _*Parameters*_ (2 - 3 inputs)
 Input Types: {{{( input, required: schema [ * ]?),( when, required: schema function),( inclusive = true: schema boolean?)}}}

 _*Output*_ {{{schema [ * ]}}}

== streamSwitch() ==

  _*Description*_ e0 -> streamSwitch( f0, ..., fn )
 ===
 ( x = e0,
   union( x -> filter $[0] == 0 -> transform $[1] -> f0(),
          ...
          x -> filter $[0] == n -> transform $[1] -> fn() ) 
 )
 
 Except that the functions can be called any number of times and in any order.
 Something like this:
 
 ( x = e0,
   union( x -> filter $[0] == 0 -> transform $[1] -> batch(n=?) -> expand f0($),
          ...
          x -> filter $[0] == n -> transform $[1] -> batch(n=?) -> expand fn($) ) 
 )
 
 The actual implementation is to stream into function fi any consecutive rows
 with index i.  Something like this:
 
 ( x = e0,
   x -> tumblingWindow( stop = fn(first,next) first[0] != next[0] )
     -> expand each p fi( p -> transform $[1] ) // where i is p[j][0] for all j in the window
 )

  _*Parameters*_ (2 - 3 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any),( arg2 = null: schema any)...}}}

 _*Output*_ {{{schema any}}}

== tag() ==

  _*Description*_ This function is used internally during the rewriting of tee().  
 It is not intended for general use.
 
 e -> tag(i)
 
 Exactly the same as:
   e -> transform [i,$]

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== tagFlatten() ==

  _*Description*_ This function is used internally during the rewriting of tee().  
 It is not intended for general use.
 
 e -> tagFlatten( int index, int numToExpand )
 
 Exactly the same as:
   e -> transform each x (
         i = x[0],
         v = x[1],
         if( i < index ) then x
         else if( i > index ) then [i + numToExpand-1, v]
         else ( assert(0 <= v[0] < numToExpand), [ v[0] + index, v[1] ] ))
 
 Example:
   [ [0,a], [1,[0,b]], [1,[1,c]], [2,d] ] -> tagFlatten( 1, 2 )
  ==
   [ [0,a], [1,b], [2,c], [3,d] ]

  _*Parameters*_ (3 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any),( arg2, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== tagSplit() ==

  _*Description*_ This function is used internally during the rewriting of tee().  
 It is not intended for general use.
 
 e -> tagSplit( f0, ..., fn )
 
 Exactly the same as:
   ( X = e, 
     X -> filter $[0] == 0 -> f0() -> transform $[1], ...
     X -> filter $[0] == n -> fn() -> transform $[1] )
     
 Also the same as:
   ( e -> write( composite( [t0, ..., tn] ) ),
     read(t0) -> f0(), ...
     read(tn) -> fn() )

  _*Parameters*_ (2 - 3 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any),( arg2 = null: schema any)...}}}

 _*Output*_ {{{schema any}}}

== tee() ==

  _*Description*_ 

  _*Parameters*_ (1 - 2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any)...}}}

 _*Output*_ {{{schema any}}}

== timeout() ==

  _*Description*_ 

  _*Parameters*_ (1 - 2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

== until() ==

  _*Description*_ Return the first elements of input (in order) until the predicate is true.
 If inclusive is true (the default) then include the element that triggered
 the condition.  Otherwise, exclude it. 
 
 input: [T...]? -> until( when: fn(T): bool, inclusive:bool = true ): [T...]

  _*Parameters*_ (2 - 3 inputs)
 Input Types: {{{( input, required: schema [ * ]?),( when, required: schema function),( inclusive = true: schema boolean?)}}}

 _*Output*_ {{{schema [ * ]}}}

----
=hadoop=
== buildModel() ==

  _*Description*_ Build a data mining model in parallel.
 
 buildModel( 
 { input: fd,
   output: fd,  // TODO: this could be eliminated, but required now and gets model
   init: fn() -> model,
   partial: fn($part,$model) -> pmodel, // $part is array of input items
   combine: fn($pmodels,$model) -> model, // $pmodels is array of partial models
   done: fn($oldModel, $newModel) -> bool
  })
 -> model

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== chainedMap() ==

  _*Description*_ Run a function *sequentially* but piecemeal over an input array.
 
 chainedMap( 
 { input: fd,
   output: fd,  // TODO: this could be eliminated, but required now and gets state
   init: state,
   map: fn(part,state) -> state, // part is array of input items
   schema?: state schema
  })
 -> state

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== loadJobConf() ==

  _*Description*_ Usage: { name: string } loadJobConf( string? filename )
 if filename to conf is not specified, then the default JobConf is loaded

  _*Parameters*_ (0 - 1 inputs)
 Input Types: {{{( arg0 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

== mapReduce() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== mrAggregate() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== nativeMR() ==

  _*Description*_ Usage: { status: boolean } nativeMR( { job conf settings } conf , { apiVersion: "0.0" | "1.0" } options );
 
 Launch a stand-alone map-reduce job that is exclusively described by job conf settings.
 
 Example: { status: true } nativeMR( loadJobConf( "myJob.conf" ) );

  _*Parameters*_ (1 - 2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

== readConf() ==

  _*Description*_ 

  _*Parameters*_ (1 - 2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

----
=io=
== arrayRead() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== del() ==

  _*Description*_ An expression that constructs an I/O descriptor for HDFS file access.

  _*Parameters*_ (1 - 2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

== expandFD() ==

  _*Description*_ 

  _*Parameters*_ (1 - 2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

== file() ==

  _*Description*_ An expression that constructs an I/O descriptor for local file access.

  _*Parameters*_ (1 - 2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

== fileSplitToRecord() ==

  _*Description*_ Return the fields of a raw FileSplit.
 
 fileSplitToRecord( split: { class: string, split: binary, * } ):
   { path: string, start: long, length: long, locations: [string...] }

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== HadoopTemp() ==

  _*Description*_ Creates a file descriptor for temporary files used by Jaql. Takes a schema argument that
 describes the schema of the individual values written to the file.

  _*Parameters*_ (0 - 1 inputs)
 Input Types: {{{( schema = schema any: schema schematype)}}}

 _*Output*_ {{{schema { * }}}}

== hbaseRead() ==

  _*Description*_ hbaseRead( tableExpr, {columns: columnExpr, lowKey:lowKeyExpr,
 highKey:highKeyExpr, timestamp:timestampExpr}? )
  - string tableName <- evaluate tableExpr - JArray columns <- evaluate
 columnExpr - string lowKey <- evaluate lowKeyExpr - string highKey <-
 evaluate highKeyExpr - LongItem timestamp <- evaluate timestamp
 
 Open a scanner on tableName, default column family and return an Iter that
 wraps each hbase row in a JMap. Each tuple is generated by constructing one
 or more ExprPairs. Each ExprPair p is generated by using the column name for
 p.name and the value for p.value

  _*Parameters*_ (1 - 2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

== hbaseWrite() ==

  _*Description*_ 

  _*Parameters*_ (2 - 3 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any),( arg2 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

== hdfs() ==

  _*Description*_ An expression that constructs an I/O descriptor for HDFS file access.

  _*Parameters*_ (1 - 2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

== hdfsShell() ==

  _*Description*_ An expression for running HDFS shell. It is equivalent to <i>hadoop fs</i>.

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== http() ==

  _*Description*_ An expression that constructs an I/O descriptor for local file access.

  _*Parameters*_ (1 - 3 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any),( arg2 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

== httpGet() ==

  _*Description*_ 

  _*Parameters*_ (1 - 3 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any),( arg2 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

== inputSplits() ==

  _*Description*_ Take a i/o descriptor and return a list of raw splits:
    [{ class: string, split: binary, locations: [string...] }...]

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== jaqltemp() ==

  _*Description*_ An expression that constructs an I/O descriptor for jaqls temp file access.

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== lines() ==

  _*Description*_ An expression that constructs an I/O descriptor for HDFS file access.

  _*Parameters*_ (1 - 2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

== localRead() ==

  _*Description*_ An expression used for reading data into jaql. The only different between
 localRead and Read is that localRead is disabled for mapReduce rewirte.

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== localWrite() ==

  _*Description*_ 

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== makeFileSplit() ==

  _*Description*_ Constructs a raw FileSplit.  You should know what you're doing if you're using this!
 
 makeFileSplit( file: string, start: long, length: long, hosts: [string...] ):
   { class: string, split: binary, locations:[string...] }

  _*Parameters*_ (4 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any),( arg2, required: schema any),( arg3, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== read() ==

  _*Description*_ An expression used for reading data into jaql. It is called as follows:
 
 <pre>
 read({type: '...', 
       location: '...', 
       inoptions: {...}})
 </pre>
 
 The type specifies which InputAdapter to use, the location specifies the
 address from which the adapter will read. The optional inoptions further
 parameterize the adapter's behavior. <br>
 If inoptions are not specified, then default options that are registered for
 the type at the AdapterStore will be used. If no options are specified and
 there are no defaults registered, it is an error. If both options are
 specified and default options are registered, then the union of option fields
 will be used. If there are duplicate names, then the query options will be
 used as an override.

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== readAdapterRegistry() ==

  _*Description*_ Load the registry from the given file
 
 readAdapterRegistry(string filename) returns file name

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== readSplit() ==

  _*Description*_ An expression used for reading data from a single split into jaql.

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== registerAdapter() ==

  _*Description*_ Register a key, value pair.
 
 registerAdapter({type: string, inOptions: {}, outOptions: {}})

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== unregisterAdapter() ==

  _*Description*_ Unregister a key, value pair.
 
 unregisterAdapter(string key) returns key

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== write() ==

  _*Description*_ An expression used for writing external data. It is called as follows:
 
 <pre>
 write({type: '...', 
        location: '...', 
        outoptions: '...', 
        inoptions: '...'}
       , expr);
 </pre>
 
 The <tt>type</tt> specifies which {@link OutputAdapter} to use, the
 <tt>location</tt> specifies the address to which the adapter will write. The
 optional <tt>outoptions</tt> further parameterize the adapter's behavior. The
 optional <tt>inoptions</tt> can be used to parametrize a read expression that
 takes as input a write expression (e.g., <tt>read(write({...}, expr)) </tt>).
 <p>
 If <tt>outoptions</tt> or <tt>inoptions</tt> are unspecified, then default
 options that are registered for the type at the {@link AdapterStore} will be
 used. If no options are specified and there are no defaults registered, it is
 an error. If both options are specified and default options are registered,
 then the union of option fields will be used. If there are duplicate names,
 then the query options will be used as an override.

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== writeAdapterRegistry() ==

  _*Description*_ Write the registry to a given file
 
 writeAdapterRegistry(string filename) returns null

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

----
=array=
== append() ==

  _*Description*_ append($a, $b, ...) ==> unnest [ $a, $b, ... ] NOT when $a or $b are
 non-array (and non-null), but that's probably an improvement. NOT when $a or
 $b are null, but the change to unnest to remove nulls will fix that should
 append(null, null) be null? it would break any unnest definition... Push
 unnest into ListExpr?

  _*Parameters*_ (1 - 2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any)...}}}

 _*Output*_ {{{schema any}}}

== arrayToRecord() ==

  _*Description*_ 

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== asArray() ==

  _*Description*_ This function ensures that input returns an array.

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== columnwise() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== deempty() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== distinct() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== enumerate() ==

  _*Description*_ 

  _*Parameters*_ (1 - 2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

== exists() ==

  _*Description*_ exists(null) = null exists([]) = false exists([...]) = true, when the array
 has at least one element (even a null) exists(...) = true, when the argument
 is not an array or a null

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== lag1() ==

  _*Description*_ lag1(arr) 
    arr is [ A ], 
    returns [ {prev: A, cur: A} ]
     
 If arr has k items, the result has k - 1 items.
 result[].prev is the first k-1 items
 result[].cur  is the last k-1 items.

 eg: [1,2,3] -> lag1()  ==  [ { prev: 1, cur: 2 }, { prev: 2, cur: 3 } ]

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== merge() ==

  _*Description*_ DEPRECATED: use union instead.
 Union multiple arrays into one array in arbitrary order without
 removing duplicates (like SQL's UNION ALL)

  _*Parameters*_ (1 - 2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any)...}}}

 _*Output*_ {{{schema any}}}

== nextElement() ==

  _*Description*_ arr -> prevAndNextElement() 
    arr is [ T ], 
    returns [ { cur: T, prev?: T, next?: T } ]
     
 If arr has k items, the result has k items.
 The first record returned does not have a prev field.
 The last record returned does not have a next field.

 eg: [1,2,3] -> nextElement() ==  
  [ { cur: 1, next: 2 }, 
    { cur: 2, next: 3 }, 
    { cur: 3 } ]

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== pair() ==

  _*Description*_ pair(A,B) == [A,B]

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== pairwise() ==

  _*Description*_ 

  _*Parameters*_ (2 - 3 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any),( arg2 = null: schema any)...}}}

 _*Output*_ {{{schema any}}}

== powerset() ==

  _*Description*_ powerset<T>([T...]? arr) returns [ [T...]... ] 
 Return the power-set (really the power-list) of a list of items.
     
 If arr has k items, the result has k - 1 items.
 result[].prev is the first k-1 items
 result[].cur  is the last k-1 items.

 eg: [1,2,3] -> powerset() ==  [ [], [1], [2], [1,2], [3], [1,3], [2,3], [1,2,3] ]

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== prevAndNextElement() ==

  _*Description*_ arr -> prevAndNextElement() 
    arr is [ T ], 
    returns [ { cur: T, prev?: T, next?: T } ]
     
 If arr has k items, the result has k items.
 The first record returned does not have a prev field.
 The last record returned does not have a next field.

 eg: [1,2,3] -> prevAndNextElement() ==  
  [ { cur: 1, next: 2,  }, 
    { cur: 2, prev: 1, next: 3 }, 
    { cur: 3, prev: 2 } ]

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== prevElement() ==

  _*Description*_ arr -> prevAndNextElement() 
    arr is [ T ], 
    returns [ { cur: T, prev?: T, next?: T } ]
     
 If arr has k items, the result has k items.
 The first record returned does not have a prev field.
 The last record returned does not have a next field.

 eg: [1,2,3] -> prevElement() ==  
  [ { cur: 1 }, 
    { cur: 2, prev: 1 }, 
    { cur: 3, prev: 2 } ]

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== removeElement() ==

  _*Description*_ 

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== replaceElement() ==

  _*Description*_ 

  _*Parameters*_ (3 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any),( arg2, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== reverse() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== rowwise() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== runningCombine() ==

  _*Description*_ 

  _*Parameters*_ (4 inputs)
 Input Types: {{{( input, required: schema [ * ]?),( init, required: schema any),( add, required: schema function),( into, required: schema function?)}}}

 _*Output*_ {{{schema [ * ]}}}

== shift() ==

  _*Description*_ 

  _*Parameters*_ (3 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any),( arg2, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== slice() ==

  _*Description*_ 

  _*Parameters*_ (3 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any),( arg2, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== slidingWindow() ==

  _*Description*_ 

  _*Parameters*_ (3 inputs)
 Input Types: {{{( input, required: schema [ * ]?),( start, required: schema function),( end, required: schema function)}}}

 _*Output*_ {{{schema [
         { * } * 
       ]}}}

== slidingWindowBySize() ==

  _*Description*_ 

  _*Parameters*_ (2 - 4 inputs)
 Input Types: {{{( input, required: schema [ * ]?),( size, required: schema long),( offset = null: schema long?),( exact = false: schema boolean)}}}

 _*Output*_ {{{schema [
         { * } * 
       ]}}}

== toArray() ==

  _*Description*_ If the input is an array or null, return it; else wrap in an array.
 
 if( $x instanceof type [*<*>]? ) $x else [$x]

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== tumblingWindow() ==

  _*Description*_ 

  _*Parameters*_ (2 - 5 inputs)
 Input Types: {{{( input, required: schema [ * ]?),( stop, required: schema function),( start = null: schema function?),( firstGroup = true: schema boolean?),( lastGroup = true: schema boolean?)}}}

 _*Output*_ {{{schema [
         [ * ] * 
       ]}}}

== tumblingWindowBySize() ==

  _*Description*_ 

  _*Parameters*_ (2 - 3 inputs)
 Input Types: {{{( input, required: schema [ * ]?),( size, required: schema long | double | decfloat),( lastGroup = true: schema boolean?)}}}

 _*Output*_ {{{schema [ * ]}}}

== union() ==

  _*Description*_ Union multiple arrays into one array in arbitrary order without
 removing duplicates (like SQL's UNION ALL)

  _*Parameters*_ (1 - 2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any)...}}}

 _*Output*_ {{{schema any}}}

----
=index=
== buildJIndex() ==

  _*Description*_ 

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== keyLookup() ==

  _*Description*_ [ [key,value1] ] -> keyLookup([ [key,value2] ]) ==> [ [key, value1, value2] ]
 
 Build a hash table on the inner key/value pairs (expr[1]).
 For each key/value in the outer pairs (expr[0])
   return [key, value1, value2] tuples.
   
 The code assumes that the inner keys are unique (or an arbitrary value is kept)
    //TODO: support duplicates?  raise error?
 
 If the outer key does not exist in the inner set, 
   null is returned for the inner value.
   So this is preserving the outer input (left outer join)
   // TODO: support full outer by finding inner values that didn't join?
 
   // TODO:support spilling large inners?

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== keyMerge() ==

  _*Description*_ [ [key,value1] ] -> keyMerge([ [key,value2] ]) ==> [ [key, value1, value2] ]
 
 Both input lists are sorted by key.
 The inner list (expr[1]) is assumed to have distinct keys.
    //TODO: support duplicates?  raise error?
 For each key/value in the outer list (expr[0])
   return [key, value1, value2] tuples.
   
 This function only requires a single key from each list to be in memory at a time.

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== probeJIndex() ==

  _*Description*_ 

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== probeLongList() ==

  _*Description*_ [ [long? key, any value] ] -> probeLongListFn([ long? key ]) ==> [ [long key, any value, long index] ]
 
 Build a compact in-memory representation of a list of longs from the build keys (expr[1]).
   Nulls in the probe list are ignored and removed from the list.
 For each key/value in the probe pairs (expr[0])
   index is >= 0 if the value is found in the list of keys.
                (actually it index of the key in the sorted list of keys, but that may change in the future)
            < 0  if not found 
                (actually it is the (-(insertion point) - 1) as defined by Arrays.binarySearch(),
                 but that may change in the future)
   return [key, value, index] tuples.
   
 Note that all probe items are returned.
 This allows us to support in and not-in predicates, as well as just simple annotations.
 Nulls are tolerated in the probe keys, but they will never find a match.
 Null [key,value] pairs are not tolerated; a pair is always expected.

 There is currently an implementation limit of 2B values (~16GB of memory).

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== sharedHashtableN() ==

  _*Description*_ sharedHashtableN(
     [Key] probeKeys,
     string buildUrl, // "hash://host:port/tableid",
     fn() returns [ [Key,Value] ] buildFn,
     schema [Key, Value] buildSchema ) // TODO: should be inferred from buildFn OR template params 
   returns [Key,Value]

 
 The file represented by fd must have [key,value2] pairs.
 The [key,value2] pairs are loaded into a hash table
 If the fd is same from call to call, the table is not reloaded.
   // TODO: cache multiple tables? perhaps with weak references
   // TODO: use hadoop's distributed cache?
   
 It is generally assumed that the file is assessible wherever this
 function is evaluated.  If it is automatically parallelized, the
 file better be available from every node (eg, in hdfs).

 Throws an exception if the file contains duplicate keys
 
 If the probe key does not exist in the hashtable, null is returned.

  _*Parameters*_ (4 - 10 inputs)
 Input Types: {{{( data, required: schema [
         [ * ]? * 
       ]?),( url, required: schema [ * ]?),( buildFn, required: schema [ * ]?),( buildSchema, required: schema [ * ]?),( age = -1: schema long),( lease = 0: schema long),( serverStart = true: schema boolean),( serverTimeout = 300000: schema long),( serverMemory = "500M": schema string),( serverThread = false: schema boolean)}}}

 _*Output*_ {{{schema [
         [
           any,
           any
         ] * 
       ]}}}

----
=xml=
== jsonToXml() ==

  _*Description*_ An expression for converting JSON to XML. It is called as follows:
 <code>jsonToXml()</code> . It is counterpart of {@link XmlToJsonFn}. But it
 does not perform a conversion which is reverse to the conversion in
 {@link XmlToJsonFn}. The reason is:
 <ol>
 <li>There is no concepts such as namespace in JSON</li>
 <li>The conversion is for a conversion from general JSON to XML. It is the
 commons case that the JSON to be converted is not converted from XML.</li>
 </ol>
 
 Only a JSON value satisfying the following conditions can be converted to
 XML:
 <ol>
 <li>It is a JSON record whose size is 1.</li>
 <li>The value of the only JSON pair in this JSON record is not JSON array.</li>
 </ol>
 
 An array nested in another array does not inherit the nesting array. For
 example, <code>{content: [[1, 2]]}</code> is converted to:
 
 <pre>
 &lt;content&gt;
   &lt;array&gt;1&lt;/array&gt;
   &lt;array&gt;2&lt;/array&gt;
 &lt;/content&gt;
 
 <pre>

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== typedXmlToJson() ==

  _*Description*_ An expression for converting XML to JSON.
 This function is similar to xmlToJson, except that it creates typed data, i.e., instead of producing all values as strings, 
 		it tries to cast each value to a closest type.

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== xmlToJson() ==

  _*Description*_ An expression for converting XML to JSON.

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== xpath() ==

  _*Description*_ Runs XPath on an XML document.
 
 xpath(xml, xpath)

  _*Parameters*_ (2 - 3 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any),( arg2 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

== xslt() ==

  _*Description*_ Runs XSLT on an XML document.
 
 xslt(xml, xsl)

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

----
=binary=
== base64() ==

  _*Description*_ Convert an ascii/utf8 base64 string into a binary string.
  
  Usage:
  binary base64(string str)

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

  _*Examples*_ 
{{{
jaql> base64("utf8string");
  hex('BAD7FCB2DAE20000')

}}}
== hex() ==

  _*Description*_ Convert a hexadecimal string into a binary string.
  
  Usage:
  binary hex(string str)

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

----
=internal=
== exprtree() ==

  _*Description*_ An internal method that can be used to print the internal tree of expressions in JSON format.

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== hash() ==

  _*Description*_ An internal method that can be used to print the internal tree of expressions in JSON format.

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== longHash() ==

  _*Description*_ An internal method that can be used to print the internal tree of expressions in JSON format.

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

----
=regex=
== regex() ==

  _*Description*_ Create a regular expression (regex).
 
 Usage:
 regex regex(string reg)
 
 regex(string reg) defines a regular expression, specified by a string, the regular-expression constructs complies
 with standard java.

  _*Parameters*_ (1 - 2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

  _*Examples*_ 
{{{
jaql> reg = regex("[a-z]+"); regex_match(reg,"abc bcd");
 ["abc"]

}}}
== regex_extract() ==

  _*Description*_ Capture every first substrings which match each group (A group is a pair of parentheses used to 
 group subpatterns.) specified in the regular expression. Return a string array like :
  ["match_group1", "match_group2" , "match_group3" ...]
 
 Usage:
 [string] regex_extract(regex reg, string text)
 
 reg is the regular expression, text is the target string. For example, given a regular expression
   (a(b*))+(c*)
 it contains 3 groups:
   group 1: (a(b*)) 
   group 2: (b*) 
   group 3: (c*)
 if input is "abbabcd", by use of regex_extract function, substrings matches each group(1-3) will be captured, this function
 will return a string array, like
   [ "ab", "b", "c"]
 where "ab" is the first hit matches group 1, as well as "b" to group 2, "c" to group 3.

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

  _*Examples*_ 
{{{
jaql> regex_extract(regex("(a(b*))+(c*)"),"abbabcd");
 [ "ab", "b", "c"]

jaql> regex_extract(regex("(a(b*))"),"abbabcd");
 [ "abb", "bb"]

}}}
== regex_extract_all() ==

  _*Description*_ Capture all the substrings which match each group (A group is a pair of parentheses used to 
 group subpatterns.) specified in the regular expression. Return a string array like 
  [[match1_group1, match1_group2 ...] , [match2_group1, match2_group2] ... ]
 
 Usage:
 [string] regex_extract(regex reg, string text)
 
 regex_extract_all(regex("(a(b*))"),"abbabcd");
 
 reg is the regular expression, text is the target string. For example, given a regular expression
   (a(b*))
 it contains 3 groups:
   group 1: (a(b*)) 
   group 2: (b*) 
 if input is "abbabcd", by use of regex_extract function, substrings matches each group(1-2) will be captured, this function
 will return a string array, like
  [ 
   ["abb","bb"],
   ["ab","b"]
  ]

 where "abb" and "bb" is the first match of group 1 and 2 when scaning the text, "ab" and "b" is the second(last) match.

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

  _*Examples*_ 
{{{
jaql> regex_extract_all(regex("(a(b*))+(c*)"),"abbabcd");
 [ 
  [ "ab", "b", "c"]
 ]

jaql> regex_extract_all(regex("(a(b*))"),"abbabcd");
  [ 
   ["abb","bb"],
   ["ab","b"]
  ]

}}}
== regex_match() ==

  _*Description*_ Returns the first substring in input that matches the pattern against the regular expression.
 
 Usage:
 
 regex_match(regex reg , string text)
 
 reg is the regular expression, text is the target string.

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

  _*Examples*_ 
{{{
jaql> regex_match(regex("[a-z]?"),"abbabcd");
 "a" //this example performs a non-greedy matching

jaql> regex_match(regex("[a-z]*"),"abbabcd");
 "abbabcd"//this example performs a greedy matching

}}}
== regex_spans() ==

  _*Description*_ 

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== regex_test() ==

  _*Description*_ Check if the target string contains substring matches given regular expression. 
 If exist at least 1 match, return true, else return false
 
 Usage:
 bool regex_test(regex reg , string text)

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

  _*Examples*_ 
{{{
jaql> regex_test(regex("[a-z]?"),"abbabcd");
 true

jaql> regex_test(regex("aaa"),"abbabcd");
 false

}}}
----
=date=
== date() ==

  _*Description*_ Format a string to date value.
 
 Usage:
 date date(string datestr)

  _*Parameters*_ (1 - 2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

  _*Examples*_ 
{{{
jaql> date('2000-01-01T11:59:59Z');
 date('2000-01-01T12:00:00.000Z');

}}}
== dateMillis() ==

  _*Description*_ Represent the date using milliseconds.
 
 Usage:
 long dateMillis(date d)
 
 the argument is restricted with date type, or it causes bad casting exception.

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

  _*Examples*_ 
{{{
jaql> dateMillis(date('2000-01-01T12:00:00Z'));
 946728000000

}}}
== dateParts() ==

  _*Description*_ Return a record which stores all readable fields of a date, including year, montch, day, dayofweek ... e.g. 
 
 Usage:
 
 record dateParts(date d)

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

  _*Examples*_ 
{{{
jaql> dateParts(date('2000-01-01T12:00:00Z'));
 {
 "day": 1,
 "dayOfWeek": 6,
 "hour": 12,
 "millis": 946728000000,
 "minute": 0,
 "month": 1,
 "second": 0,
 "year": 2000,
 "zoneOffset": 0
 }

}}}
== now() ==

  _*Description*_ Return current system date time.
 
 Usage:
 date now()

  _*Parameters*_ (0 inputs)
 Input Types: {{{}}}

 _*Output*_ {{{schema any}}}

----
=nil=
== denull() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== emptyOnNull() ==

  _*Description*_ emptyOnNull(e) == firstNonNull(e, [])

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== firstNonNull() ==

  _*Description*_ 

  _*Parameters*_ (0 - 1 inputs)
 Input Types: {{{( arg0 = null: schema any)...}}}

 _*Output*_ {{{schema any}}}

== nullElementOnEmpty() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== nullOnEmpty() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== onEmpty() ==

  _*Description*_ 

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

----
=catalog=
== catalogInsert() ==

  _*Description*_ An expression to insert an entry into catalog. It is an error if an entry
 with the same key already exists.

  _*Parameters*_ (1 - 2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

== catalogLookup() ==

  _*Description*_ An expression to read the entry identified by a key in catalog.

  _*Parameters*_ (1 - 2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

== catalogUpdate() ==

  _*Description*_ An expression to update catalog entry. It can only add records or fields. No
 old records or fields will be overwritten.

  _*Parameters*_ (1 - 2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

== updateComment() ==

  _*Description*_ An expression that updates comment field of entry in catalog.

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

----
=number=
== abs() ==

  _*Description*_ Return the absolute value of a numeric value
 
 Usage:
 number abs(number)

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

  _*Examples*_ 
{{{
jaql> abs(-100);
 100

jaql> abs(-3.14)
 3.14

}}}
== decfloat() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== div() ==

  _*Description*_ 

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== double() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== exp() ==

  _*Description*_ raise base of natural log (e) to arg: e^a pow(x,y) = exp( y * ln(x) )

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== ln() ==

  _*Description*_ Return the natural logarithm of a numeric value
 
 Usage:
 number abs(number)

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== long() ==

  _*Description*_ Parse the given atom value to long value
 
 Usage:
 long long(anyatom)

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

  _*Examples*_ 
{{{
jaql> long(3.14)
 3

jaql> long(3)
 3

jaql> long(true)
 1

}}}
== mod() ==

  _*Description*_ Return the modulus of a and b, both a and b are numeric values 
 
 Usage:
 number mod(number a, number b)

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

  _*Examples*_ 
{{{
jaql> mod(3,2)
 1

}}}
== number() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== pow() ==

  _*Description*_ Raise a number to power
 
 Usage:
 number pow(number a , number b)

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

  _*Examples*_ 
{{{
jaql> mod(3,2)
 1

}}}
== toNumber() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

----
=module=
== examples() ==

  _*Description*_ 

  _*Parameters*_ (1 - 2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

== listExports() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== test() ==

  _*Description*_ 

  _*Parameters*_ (1 - 2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

----
=random=
== randomDouble() ==

  _*Description*_ 

  _*Parameters*_ (0 - 1 inputs)
 Input Types: {{{( arg0 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

== randomLong() ==

  _*Description*_ 

  _*Parameters*_ (0 - 1 inputs)
 Input Types: {{{( arg0 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

== registerRNG() ==

  _*Description*_ 

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== sample01RNG() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== sampleRNG() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== uuid() ==

  _*Description*_ Generate a type 4 UUID (random method)

  _*Parameters*_ (0 inputs)
 Input Types: {{{}}}

 _*Output*_ {{{schema any}}}

----
=record=
== arity() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== fields() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== names() ==

  _*Description*_ names($rec) == for $k,$v in $rec return $k == fields($rec)[*][0];

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== record() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== remap() ==

  _*Description*_ 

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== removeFields() ==

  _*Description*_ 

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== renameFields() ==

  _*Description*_ 

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== replaceFields() ==

  _*Description*_ Replace fields in oldRec with fields in newRec only if the field name exists in oldRec.
 Unlike remap, this only replaces existing fields.

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== values() ==

  _*Description*_ values($rec) == for $k,$v in $rec return $v == fields($rec)[*][1];

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

----
=del=
== jsonToDel() ==

  _*Description*_ A function for converting JSON to CSV. It is called as follows:
 <p>
 <code>jsonToDel({schema: '...', delimiter: '...', quoted: '...', escape: '...'})</code> .

  _*Parameters*_ (1 - 2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

----
=schema=
== assert() ==

  _*Description*_ Returns its first argument and adds the schema information given in the second argument
 without validation. Use carefully!

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== check() ==

  _*Description*_ Checks whether the first argument matches the schema given in the second argument. If so,
 returns the first argument. Otherwise, throws an expection.

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== dataGuide() ==

  _*Description*_ Usage: dataGuide(any value) returns [string]
 
 Return a string that represents each unique path in the value.
 For records:
    yield ""
    for each field:value in record:
       yield "." + field + dataGuide(value)
 For arrays:
    yield "[]"
    for each value in array
       yield "[]" + dataGuide(value) 
 For atomic types:
     yield ":" + the type name, eg, ":string", ":null"

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== elementsOf() ==

  _*Description*_ elementsOf(schema): if schema is (potentially) an array schema, return the schema of its elements (if any)

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== fieldsOf() ==

  _*Description*_ elementsOf(schema): if schema is (potentially) an record schema, return a table describing its known fields:
     [{ name: string, schema: schema, index: long }...]

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== isNullable() ==

  _*Description*_ isNullable(schema): true if schema might match null, false otherwise

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== schemaof() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== sqlTypeCode() ==

  _*Description*_ sqlTypeCode(schema): return the sql type code for schema

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== typeof() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

----
=agg=
== any() ==

  _*Description*_ Picks any value. If there is at least one non-null values, picks a non-null value.

  _*Parameters*_ (1 inputs)
 Input Types: {{{( a, required: schema [ * ]?)}}}

 _*Output*_ {{{schema any}}}

== argmax() ==

  _*Description*_ 

  _*Parameters*_ (2 inputs)
 Input Types: {{{( a, required: schema [ * ]?),( f, required: schema function)}}}

 _*Output*_ {{{schema any}}}

== argmin() ==

  _*Description*_ 

  _*Parameters*_ (2 inputs)
 Input Types: {{{( a, required: schema [ * ]?),( f, required: schema function)}}}

 _*Output*_ {{{schema any}}}

== array() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== avg() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== combine() ==

  _*Description*_ 

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== count() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== covStats() ==

  _*Description*_ covStats(array x) = sum [1 x1 x2 ... xn] * [1 x1 x2 ... xn]^T
   = [ count   sum(x1)    sum(x2)    ... sum(xn)    ,
               sum(x1*x1) sum(x1*x2) ... sum(x1*xn) ,
                          sum(x2*x2) ... sum(x2*xn) ,
       ...                                          ,
                                         sum(xn*xn) ]

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== expSmooth() ==

  _*Description*_ Perform exponential smoothing on a sequence of numbers:
   s[0] = x[0]
   s[i] = a * x[i] + (1-a) * s[i-1]
 The numbers are cast to a double and the result is always a double.

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== icebergCubeInMemory() ==

  _*Description*_ 

  _*Parameters*_ (3 - 4 inputs)
 Input Types: {{{( input, required: schema [ * ]?),( columns, required: schema [
         string * 
       ]),( perGroupFn, required: schema function),( minSupport = 1: schema long | double | decfloat)}}}

 _*Output*_ {{{schema [
         [ * ] * 
       ]}}}

== inferElementSchema() ==

  _*Description*_ Infer a schema that describes all of the elements.

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== javauda() ==

  _*Description*_ 

  _*Parameters*_ (1 - 2 inputs)
 Input Types: {{{( class, required: schema string),( args = null: schema any)...}}}

 _*Output*_ {{{schema function}}}

== javaudacall() ==

  _*Description*_ 

  _*Parameters*_ (2 - 3 inputs)
 Input Types: {{{( array, required: schema [ * ]?),( class, required: schema string),( args = null: schema any)...}}}

 _*Output*_ {{{schema any}}}

== max() ==

  _*Description*_ Find the max value in an array.
 Usage:
 
 any max( [ any ] );
 
 Max takes an array as input and returns the max value from the array. The type of the array's elements is not restricted.

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

  _*Examples*_ 
{{{
jaql> max([1,2,3]);
 3

jaql> max(["a","b","c"]);
 "c"

jaql> read(hdfs("someFileOfLongs")) -> group into max($);

jaql> read(hdfs("someFileOfPairs")) -> group by g = $[0] into { first: g, maxSecond: max($[*][1]) };

}}}
== min() ==

  _*Description*_ Find the minimum value in an array.
 Usage:
 
 any max( [ any ] );
 
 Max takes an array as input and returns the minimum value from the array. The type of the array's elements is not restricted.

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

  _*Examples*_ 
{{{
jaql> min([1,2,3]);
 1

jaql> min(["a","b","c"]);
 "a"

jaql> read(hdfs("someFileOfLongs")) -> group into min($);

jaql> read(hdfs("someFileOfPairs")) -> group by g = $[0] into { first: g, minSecond: min($[*][1]) };

}}}
== pickN() ==

  _*Description*_ 

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== singleton() ==

  _*Description*_ Convert a pipe to a simple value:
   If the pipe is empty then null
   If the pipe has one item then that item
   If the pipe has more than one item then error

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== sum() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== topN() ==

  _*Description*_ 

  _*Parameters*_ (3 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any),( arg2, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== uda() ==

  _*Description*_ 

  _*Parameters*_ (4 inputs)
 Input Types: {{{( init, required: schema function),( accumulate, required: schema function),( combine, required: schema function),( final, required: schema function)}}}

 _*Output*_ {{{schema function}}}

== udacall() ==

  _*Description*_ 

  _*Parameters*_ (5 inputs)
 Input Types: {{{( array, required: schema [ * ]?),( init, required: schema function),( accumulate, required: schema function),( combine, required: schema function),( final, required: schema function)}}}

 _*Output*_ {{{schema any}}}

== vectorSum() ==

  _*Description*_ vectorSum(array x) = [sum(x1), sum(x2), ..., sum(xn)]

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

----
=db=
== jdbc() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

----
=span=
== span() ==

  _*Description*_ 

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== span_begin() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== span_contains() ==

  _*Description*_ 

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== span_end() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== span_extract() ==

  _*Description*_ span_extract("some big string", span(2,4))
 "me"
 
 Current implementation uses SubJsonString. If the caller modifies the input string at
 some later point, the result of this call will be invalid.

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== span_overlaps() ==

  _*Description*_ 

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== span_select() ==

  _*Description*_ 

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== tokenize() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

----
=string=
== convert() ==

  _*Description*_ Converts an input value (string, array of strings or record with string values) to 
 the specified types.

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== endsWith() ==

  _*Description*_ 

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== json() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== serialize() ==

  _*Description*_ 

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== startsWith() ==

  _*Description*_ bool startsWith(string target, string prefix)
  Check if a target string starts with a given prefix, return true or false

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== strcat() ==

  _*Description*_ Concats one or more strings to a new string
 
 Usage:
 string strcat(string ... str)

  _*Parameters*_ (0 - 1 inputs)
 Input Types: {{{( arg0 = null: schema any)...}}}

 _*Output*_ {{{schema any}}}

== strJoin() ==

  _*Description*_ Build a string that concatentates all the items, adding sep between each item.
 Nulls are removed, without any separator.
 If you want nulls, use firstNonNull(e,'how nulls appear').
 
 Usage:
 string strJoin(array items, string sep)

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== strLen() ==

  _*Description*_ long strLen(string str)
 return the lenght of the given string

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== strPos() ==

  _*Description*_ Usage: long strPos(string str, string toFind, long startIndex=0)

  _*Parameters*_ (2 - 3 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any),( arg2 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

== strPosList() ==

  _*Description*_ Usage: long StrPosFn(string str, string toFind, long startIndex=0)

  _*Parameters*_ (2 - 3 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any),( arg2 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

== strReplace() ==

  _*Description*_ Usage: [string] strReplace(string val, regex pattern, string replacement)

  _*Parameters*_ (3 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any),( arg2, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== strSplit() ==

  _*Description*_ Usage: [string] strSplit(string val, string delimitter)

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== strSplitN() ==

  _*Description*_ strSplitN(string src, string sep, int n) ==> [string1, string2, ..., stringn]
 sep is a string of one charater.

  _*Parameters*_ (3 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any),( arg2, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== strToLowerCase() ==

  _*Description*_ Convert a string to lower case.

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== strToUpperCase() ==

  _*Description*_ Convert a string to upper case.

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== substring() ==

  _*Description*_ 

  _*Parameters*_ (2 - 3 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any),( arg2 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

----
=function=
== addClassPath() ==

  _*Description*_ Add jars to the classpath

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== fence() ==

  _*Description*_ 

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== fencePush() ==

  _*Description*_ 

  _*Parameters*_ (2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1, required: schema any)}}}

 _*Output*_ {{{schema any}}}

== javaudf() ==

  _*Description*_ An expression that constructs a JSON value for a Java UDF

  _*Parameters*_ (1 inputs)
 Input Types: {{{( arg0, required: schema any)}}}

 _*Output*_ {{{schema any}}}

----
=net=
== jaqlGet() ==

  _*Description*_ 

  _*Parameters*_ (1 - 2 inputs)
 Input Types: {{{( arg0, required: schema any),( arg1 = null: schema any)}}}

 _*Output*_ {{{schema any}}}

----
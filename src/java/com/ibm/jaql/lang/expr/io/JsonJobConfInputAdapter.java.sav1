/*
 * Copyright (C) IBM Corp. 2009.
 * 
 * Licensed under the Apache License, Version 2.0 (the "License"); you may not
 * use this file except in compliance with the License. You may obtain a copy of
 * the License at
 * 
 * http://www.apache.org/licenses/LICENSE-2.0
 * 
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
 * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
 * License for the specific language governing permissions and limitations under
 * the License.
 */

package com.ibm.jaql.lang.expr.io;

import java.io.IOException;
import java.lang.reflect.UndeclaredThrowableException;

import org.apache.hadoop.mapred.InputFormat;
import org.apache.hadoop.mapred.InputSplit;
import org.apache.hadoop.mapred.JobConf;
import org.apache.hadoop.mapred.RecordReader;
import org.apache.hadoop.mapred.Reporter;

import com.ibm.jaql.io.AdapterStore;
import com.ibm.jaql.io.hadoop.ConfSetter;
import com.ibm.jaql.io.hadoop.ConfUtil;
import com.ibm.jaql.io.hadoop.DefaultHadoopInputAdapter;
import com.ibm.jaql.io.hadoop.Globals;
import com.ibm.jaql.io.hadoop.HadoopSerializationDefault;
import com.ibm.jaql.io.hadoop.JsonHolder;
import com.ibm.jaql.json.type.JsonRecord;
import com.ibm.jaql.json.type.JsonString;
import com.ibm.jaql.json.type.JsonValue;

public class JsonJobConfInputAdapter extends DefaultHadoopInputAdapter<JsonHolder, JsonHolder>
{
  public static final JsonString FORMAT_KEY = new JsonString("mapred.input.format.class");
  
  @Override
  public void init(JsonValue value) throws Exception
  {
    super.init(value);
//    JsonRecord args = (JsonRecord) value;
//    this.options = AdapterStore.getStore().input.getOption(args);
//    this.iFormat = (InputFormat<JsonHolder,JsonHolder>) AdapterStore.getStore().getClassFromRecord(
//        options, FORMAT_KEY, null).newInstance();
  }
  
  @Override
  protected void set(JobConf conf) throws Exception
  {
    super.set(conf);
    ConvertInputFormat.updateJobConf(conf, options); // FIXME: move fn
//    HadoopSerializationDefault.register(conf);
//    Globals.setJobConf(conf);
//    ConfUtil.writeConf(conf, ConfSetter.CONFINOPTIONS_NAME, options);
  }

  /*
   * (non-Javadoc)
   * 
   * @see com.ibm.jaql.io.hadoop.DefaultHadoopInputAdapter#configure(org.apache.hadoop.mapred.JobConf)
   */
  @Override
  public void configure(JobConf conf)
  {
    JsonRecord options;
    try
    {
      options = ConfUtil.readConf(conf, ConfSetter.CONFINOPTIONS_NAME);
    }
    catch (Exception e)
    {
      throw new UndeclaredThrowableException(e);
    }
//    ConvertInputFormat.updateJobConf(conf, options); // FIXME: move fn
  }
  
//  @Override
//  public void close() throws Exception
//  {
//    super.close();
//  }

  /*
   * (non-Javadoc)
   * 
   * @see com.ibm.jaql.io.hadoop.DefaultHadoopInputAdapter#getRecordReader(org.apache.hadoop.mapred.InputSplit,
   *      org.apache.hadoop.mapred.JobConf, org.apache.hadoop.mapred.Reporter)
   */
  @Override
  public RecordReader<JsonHolder, JsonHolder> getRecordReader(
      final InputSplit split,
      final JobConf job,
      final Reporter reporter) throws IOException
  {
    return super.getRecordReader(split, job, reporter);
  }

}
